understanding of how the algorithms account for the world might provide an important part of accountability. If putting in place a formal process of accountability and drawing on traditional notions of ethics were too limited for rendering the algorithm accountable, then what next? My suggestion to the project participants was that we needed to understand how the algorithm was at 3 ACCOUNTABILITY AND THE ALGORITHM 51 once a participant in everyday life and used that participation to compose accounts of everyday life. Algorithmic accountability must thus move between two registers of accountability. This frst, sense of accountability through which the algorithm might be held to account needed to be combined with a second sense of accountability through which the algorithm engages in the process of making sense of the world. I suggested we could explore this second sense of accountability through ethnomethodology. In particular, I looked to the ethnomethodological use of the hyphenated version of the term: account-able (Garfnkel 1967; Eriksen 2002). Garfnkel suggests that “the activities whereby members produce and manage settings of organized everyday affairs are identical with members’ procedures for making those settings ‘account-able’” (1967: 1). For ethnomethodologists, this means that actions are observable-reportable; their character derives from the ability of other competent members to assess and make sense of actions. Importantly, making sense of actions involves the same methods as competently taking part in the action. To be account-able thus has a dual meaning of being demonstrably open to inspection as an account of some matter and being able to demonstrate competence in making sense of some matter (see Lynch 1993; Dourish 2004 for more on this). This might be a starting point for a kind of algorithmic account-ability in action. Although ethnomethodologists have studied the account-able character of everyday conversations, they have also developed a corpus of workplace studies (Heath and Button 2002). Here, the emphasis is on the account-able character of, for example, keeping records, following instructions, justifying actions in relation to guidelines and informing others what to do and where to go (Lynch 1993: 15). For Button and Sharrock (1998), actions become organisationally account-able when they are done so that they can be seen to have been done on terms recognisable to other members within the setting as competent actions within that organisation. Extending these ideas, studying the algorithm on such terms would involve continuing our study of the work of computer scientists and others involved in the project as we started in Chapter 2, but with an orientation towards making sense of the terms of account-ability within which the algorithm comes to participate in making sense of a particular scene placed under surveillance. This is not to imply that the algorithm operates alone. Instead, I will suggest that an understanding of algorithmic account-ability can be developed by 52 D. NEYLAND studying how the algorithmic system produces outputs that are designed to be used as part of organisational practices to make sense of a scene placed under surveillance by the algorithmic system. In this way, the human-shaped object and luggage-shaped object of Chapter 2 can be understood as part of this ongoing, account-able production of the sense of a scene in the airport or train station in which the project is based. I will refer to these sense-making practices as the account-able order of the algorithmic system. Importantly, having algorithms participate in account-ability changes the terms of the account-able order (in comparison with the way sense was made of the space prior to the introduction of the algorithmic system). Making sense of this account-able order may still appear to be some distance from the initial concerns with accountability which I noted in the opening to this chapter, of algorithmic openness and transparency. Indeed, the ethnomethodological approach appears to be characterised by a distinct set of concerns, with ethnomethodologists interested in moment to moment sense-making, while calls for algorithmic accountability are attuned to the perceived needs of those potentially subject to actions deriving from algorithms. The accountable order of the algorithm might be attuned to the ways in which algorithms participate in making sense of (and in this process composing) everyday life. By contrast, calls for algorithmic accountability are attuned to formal processes whereby the algorithm and its consequences can be assessed. However, Suchman et al. (2002) suggest that workplace actions, for example, can involve the simultaneous interrelation of efforts to hold each other responsible for the intelligibility of our actions (account-ability) while located within constituted ‘orders of accountability’ (164). In this way, the account-able and the accountable, as different registers of 