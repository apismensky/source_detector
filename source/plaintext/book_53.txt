demonstration. The computer scientist went on to make a further suggestion to the project coordinator: Computer Scientist1: do you want to tell the truth? [no response] The pause in the meeting following this second suggestion was slightly shorter than the frst and was breached by the project coordinator who began to set out a fairly detailed response to the situation, giving the impression that he had been gathering his thoughts for some time. In his view a live test in the airport, using live video streams was the only possibility for the demonstration to funders. For the train station, his view was different: Project Coordinator: We should record an idealised version of the system, using recorded data. We can just tell the reviewers there’s not enough time to switch [confgurations from airport to train station]. What we are saying matches the [original project description]. We will say that a huge integration was required to get two installations. In this excerpt the project coordinator suggests that for the train station, not only will recorded footage be used, but the demonstration will be ‘idealised’. That is, a segment of recorded data will be used that fts computer scientists’ expectations of what the algorithms are most likely to correctly see and correctly respond to (where ‘correct’ in both cases would be in line with the expectations of the project team). Idealising 5 DEMONSTRATING THE ALGORITHM 109 the demonstration is closer to a laboratory experiment than the initial system experimentation we saw in Chapter 2. It involved controlling conditions in such a way as to extend the clean and pure, controlled boundaries of the laboratory into the everyday life of the train station (drawing parallels with Muniesa and Callon’s (2007) approach to the economist’s laboratory) to manage a display of virtuosity (Collins 1988). This is the frst way in which questions of integrity were opened: only footage from the best-positioned cameras, featuring people and things on one kind of foor surface, in one lighting condition, at times when the station was not busy, would be used. However, there was also a second question of integrity at stake here: the demonstration would also feature recorded system responses. This meant that the computer scientists could keep recording responses the system made—how our algorithms went about showing they had seen, grasped, classifed and responded to everyday life correctly—until the computer scientists had a series of system responses that matched what the computer scientists expected the algorithms to see and show. Any ‘errors’ by the algorithms could be removed from the recording. At this moment, several meeting participants looked as if they wanted to offer a response. However, the project coordinator cut off any further discussion: Project Coordinator: I don’t think there’s any need to say anything on any subject that was not what I just said. The immediate practical outcome of this meeting was to distribute tasks for the idealised, recorded train station demonstration (project members from StateTrack, the train operator, were to start recording video streams and provide computer scientists with more detail on their surveillance camera layouts, computer scientists were to start fguring out which cameras to use in the recordings, and so on). The distribution of tasks was seemingly swift and effcient and unlike the initial sections of the meeting which were characterised by what appeared to be awkward pauses. For the train station demonstration, revelation and concealment (Coopmans 2010) would be carefully managed, through the positioning of witnesses (Smith 2009). The ethical future to be brought into being would be staged with a naturalistic certainty—as if the images were just those that one would see on entering the train station, rather than a narrow selection of images from certain cameras, at certain angles, at certain times, of certain people and certain objects. 110 D. NEYLAND However, this focus on an idealised, recorded demonstration for the train station, left the demonstration for the airport under-specifed, aside from needing to be ‘live’. Two follow-up meetings were held in the airport to ascertain how a ‘live’ demonstration of the technology could be given to the project funders. Allowing the algorithms to run on their own and pick out events as they occurred in the airport continued to provide disappointing results. The project coordinator maintained the need for a ‘live’ demonstration and in particular wanted to put on a live demonstration of the system detecting abandoned luggage, describing this as the ‘king’ of Event Detection (on the basis that it was perceived by the computer scientists and funders as the most complex event type to detect). In a second airport meeting, a month before the fnal demonstration, the project team and particularly the project coordinator became more concerned that the algorithms would not work ‘live’. In response to these 