airport employee was leaving the luggage in the precisely defned location on a consistent basis, that the luggage selected was appropriate, that it was being left in a natural way (its position was not continually adjusted following telephone instructions) and the algorithm was successfully classifying the luggage-shaped object and issuing an alert that funders would be able to see in the demonstration. At this moment it appeared that the demonstration would be ‘live’ and ‘idealised’, but what of its integrity? I was still present to report on the ethics of the technology under development and the project itself. In the fnal preparation meeting prior to the demonstration for research funders, I suggested that a common motif of contemporary ethics was accountability and transparency (Neyland 2007; Neyland and Simakova 2009; also see Chapter 3) and this sat awkwardly with the proposed revelation and concealment and positioning of witnesses being proposed. On the whole, the project team supported the idea of making the demonstration more accountable and transparent—this was, after all, a research project. The project team collectively decided that the demonstration would go ahead, but the research funders would be told of the actor’s status as an employee of the airport, that the abandonment itself was staged, that instructions would be given to the actor in plain sight of the funders. Revelation and concealment were re-balanced and perhaps a degree of integrity was accomplished. Integrity, Everyday Life and the Algorithm In this chapter, the complexity of the everyday life of our algorithms appeared to escalate. Moving from initial experimentation, in which the aim was to grasp the human-shaped and other shaped objects, towards testing and demonstrations in which the everyday life of the airport and train station had to be accounted for, proved challenging. Building on the partial failures of the deleting machine in Chapter 4 that pointed towards emerging problems with the system, here demonstrations for end-users of the full system highlighted signifcant problems. But these were only one of three types of demonstration (to generate ethical discussion, for end-user operatives and for project funders). The complexities of these demonstrations can be analysed through the three themes we initially marked out in the STS literature on future orientations of technology. Each of the forms of demonstration intersects 114 D. NEYLAND these themes in distinct ways. For example, the demonstrations for ethical audiences were initially conceived as free from many of the concerns of revelation and concealment, temporal oscillation and carefully scripted witnessing. I had (naively) imagined these demonstrations were occasions in which the technology would be demonstrated in an open manner, inspiring free discussion of its potential ethical implications. Yet the demonstration to end-users and prior attempt to collect effcacy data to render the algorithmic system comparable with the conventional surveillance system (but with added ethics), revealed the extent of concealment, temporal oscillation and carefully scripted witnessing that had been required to put together the videos of the system for the ethical demonstrations. I could now see these videos as demonstrably accounting for an algorithmic technology with capabilities far beyond those displayed to end-users. We could characterise the ethical demonstration as a kind of idealised display of virtuosity (Collins 1988), but one which no project member had confdence in, following the search for effcacy data for end-users. Subsequent discussions of the form and content of the demonstrations for project funders suggests that a compromise on integrity was required. The project coordinator looked to carefully manage revelation and concealment (for the train station only using recorded footage, within conditions that algorithms could see, only using recorded system responses and only using those responses when the system had responded correctly; or in the airport controlling the type of luggage, its location, its careful ‘abandonment’), temporal oscillation (using the footage to conjure an ethical surveillance future to be made available now) and the elaboration of a world into which witnesses could be scripted (with the computer scientists, project manager, algorithms and myself initially in a different position from which to see the world being offered to project funders). Yet discussion of demonstrations and their integrity should not lead us to conclude that this is simply and only a matter of deception. Attending to the distinct features of integrity through notions of morality, materiality and vision can help us to explore what kind of everyday life our algorithms were now entering into. Firstly, our algorithms have been consistently oriented towards three ethical aims (to see less and address privacy concerns, store less and address surveillance concerns, and only use 