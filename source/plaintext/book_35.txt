& N. Rose (Eds.), Foucault and Political Reason (pp. 37–64). London: UCL Press. Rose, N. (1999). Powers of Freedom. Cambridge: Cambridge University Press. Rose, N., & Miller, P. (1992). Political Power Beyond the State: Problematics of Government. British Journal of Sociology, 43(2), 173–205. Sandvig, C., Hamilton, K., Karahalios, K., & Langbort, C. (2013, May 16–17). ReCentering the Algorithm. Paper Presented at ‘Governing Algorithms’ Conference, New York. Available from: http://governingalgorithms.org/ wp-content/uploads/2013/05/4-response-karahalios-et-al.pdf. Shaw, M., & Plepinger, E. (2001). Ethical Guidelines: ADR (Alternative Dispute Resolution) Provider Organisations Should Increase Transparency, Disclosure, Dispute Resolution Magazine, Spring Edition, Available from: http://www. adrassoc.com/Publications%5CShawPaplinger.pdf. 3 ACCOUNTABILITY AND THE ALGORITHM 71 Slavin, K. (2011). How Algorithms Shape Our World. Available from: http:// www.ted.com/talks/kevin_slavin_how_algorithms_shape_our_world.html. Spring, T. (2011). How Google, Facebook and Amazon Run the Internet. Available from: http://www.pcadvisor.co.uk/features/internet/3304956/ how-google-facebook-andamazonrun-the-internet/. Stalder, F., & Mayer, C. (2009). The Second Index. Search Engines, Personalization and Surveillance. In K. Becker & F. Stalder (Eds.), Deep Search. The Politics of Search Beyond Google (pp. 98–115). Piscataway, NJ: Transaction Publishers. Strathern, M. (2000). The Tyranny of Transparency. British Educational Research Journal, 26(3), 309–321. Strathern, M. (2002). Abstraction and Decontextualisation: An Anthropological Comment. In S. Woolgar (Ed.), Virtual Society? Technology, Cyberbole, Reality (pp. 302–313). Oxford: Oxford University Press. Suchman, L., Trigg, R., & Blomberg, J. (2002). Working Artefacts: Ethnomethods of the Prototype. British Journal of Sociology, 53(2), 165–179. Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/ by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. 73 Abstract Deletion was a central component of the algorithmic system studied in this book. Deletion is also a key motif of contemporary data management: concepts such as proportionality, necessity, a shelf-life for data, right to be forgotten or right to erasure and specifc defnitions of privacy all relate to deletion. In this chapter, the calculative basis for deletion will be used to provide insight into not just the content of an algorithm, but its everyday composition, effects and associated expectations. However, the chapter suggests that deletion also poses a particular kind of problem: the creation of nothing (the deleted) needs to be continually proven. These focal points and the diffculties of providing proof are used to address suggestions in contemporary research that algorithms are powerful and agential, easily able to enact and execute orders. Instead, the chapter calls for more detailed analysis of what constitutes algorithmic success and failure. Keywords Deletion · Proof · Calculation · Success and failure Opening In Chapter 3, I suggested that our algorithms had begun to participate in everyday life by becoming involved in establishing the account-able order of life in the airport and train station. I also suggested that this form of account-ability intersected with concerns of CHAPTER 4 The Deleting Machine and Its Discontents © The Author(s) 2019 D. Neyland, The Everyday Life of an Algorithm, https://doi.org/10.1007/978-3-030-00578-8_4 74 D. NEYLAND accountability, in particular in relation to the project’s ethical aims and the possibility of future data subjects being able to question the algorithm. You will recall that the project was funded in order to develop an algorithmic system that would reduce the amount of visual video data seen within a surveillance system and stored within such systems, without developing new algorithms. As we saw in the last chapter, the extent to which these ethical aims were achieved was not straightforward to assess as the system went through various forms of experimentation and change, the ethics board set up to hold the system to account raised new questions as the system developed and my own understanding of the system grew over time. One aspect of this unfolding 