way by the algorithms that the journey could be made back in the other direction, from algorithm back to train station and airport. These were the demands that an elegant solution had to meet. So our algorithms were beginning to be competent in grasping and composing everyday life. But their own lives were not without constraints. They were not just in the business of producing results, but demonstratively proving that they had produced the right kind of results. These were outputs that accountably and demonstrably accomplished the project’s three ethical aims, to see less, to store less and to do so without creating any new algorithms. Elegance alone was insuffcient. To an ethnographer assessing their ethics, to an ethics board and later in ethical demonstrations, our algorithms had to continually and accountably prove their capabilities. The abandoned luggage, moving the wrong way and movement into a forbidden area algorithms had to work with other system components in Chapter 3, the User Interface, the Route Reconstruction system, probabilistic trees, algorithmic children, parameterisation, classifcation of objects and action states, to collectively demonstrate that everyday life could be improved by the emerging system. This was composition of everyday life, then, but one that was also morally improved. The world was not just grasped, but ethically enhanced. The accountable order that the algorithms could participate in, while in their experimental activities, had to intersect with a more formal sense of accountability. An opportunity had to be developed for 134 D. NEYLAND future data subjects of algorithmic decision-making and their representatives to question the system. The algorithms also had to engage with the ethics board to begin to give effect to the ethically enhanced world. Unfortunately for our algorithms, these effects and the confdence with which they were demonstrated, began to dissipate as the system moved beyond experimentation. In Chapter 4, it became clear that the system’s ethical aims might have a value beyond experimentation, in accomplishing compliance with new regulatory demands to delete data. Deletion might provide a means to accomplish a market value for our algorithms. Yet it was here that problems began to emerge. As preparations were made to use the algorithms to distinguish between relevant and irrelevant data and provide demonstrative proof that irrelevant data could be effectively and accountably deleted, project members started to disagree. Just what should constitute adequate deletion? Changing the route by which a user connects to data, overwriting, corrupting or expunging data from the system? As the project coordinators sought the most thorough means of deletion possible, as a prior step to developing a market for the system, the computer scientists struggled to match their demands. A system log was developed to produce accountable reports for humans of the algorithms’ ability to delete. But the system did no more than continually report the failures of the system: data was not deleted in its entirety, orphan frames were left behind, and the demarcation of relevant from irrelevant data came under scrutiny. The production of nothing (the deleted), required the production of something (an account of deletion), but the failure to successfully accomplish nothing (with deletion undermined by the stubborn presence of orphan frames) created a troubling something—a continually disruptive presence that questioned our algorithms’ abilities to produce nothing. Much of everyday life—somewhere between 95 and 99%—it turns out is irrelevant and can be deleted. By failing to grasp all this irrelevance and instead leaving a trail of data and reports that attested to this failure, the prospects of our algorithms becoming the everyday of the airport and train station were diminished. This was the start of some escalating troubles for the algorithms. As they continued their journey from experimentation, they had to enter into the ever greater wilds of everyday life. From experimentation in settings with matching fooring and lighting, project participants acting out the roles of normal humans, and cameras supplying data from the right angle and height and distance, at the right frame rate for our algorithms to see, 6 MARKET VALUE AND THE EVERYDAY LIFE OF THE ALGORITHM 135 our algorithms now had to grasp real space, in real time. Here people, things and events unfolded in a naturally occurring away, across different foorings and lighting conditions, at different frame rates, with humans who now acted in oddly normal ways. Children went this way and that way, adults stood still for too long, luggage did not behave as it ought and humans wore the wrong kinds of outfts that looked just like the airport foor. Grasping and composing this everyday was too challenging. Under test conditions, in place of 6 items of potentially abandoned luggage came 2654 items. The relevant and irrelevant 