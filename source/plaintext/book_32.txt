particularly frenzied periods of project activity, 3 ACCOUNTABILITY AND THE ALGORITHM 65 I found it more challenging to maintain a clear notion of what constituted the ‘order’ of the algorithmic system to report to the ethics board, as major features (e.g. which components of the system talked to each other) would be changed in quite fundamental ways. When the Route Reconstruction and Privacy Enhancement components of the system were also brought together with the relevancy detection algorithms, reporting became more diffcult again. The ongoing changes of system development emphasised the value of building an understanding of the system’s developing account-able order. Making sense of the way in which the algorithmic system (its components, design decisions, designers, software, instructions and so on) was involved in making sense of the train station and airport, avoided providing a more or less certain account developed from a single or brief timeframe that simply captured and replayed moments of system activity, as if the system had a singular, essential characteristic. Instead, understanding the account-able order held out the promise of making sense of the ordering practices of the system under development, how algorithms went about making sense of and participating in everyday life. In the absence of such an approach to algorithms, the risk would be that multiple assumptions (that might be wrong or only correct for a short time) regarding the nature of algorithms were set in place and formed the basis for accountability. Tracing system developments and the changing account-able order of the algorithmic system for presentation to the ethics board also became the principal means of intersecting the different registers of account-ability and accountability. In place of presenting a static picture of the algorithmic system, changes in the ordering activities of the system could be demonstrated and discussed in relation to the project’s ethical aims. This was particularly important in ethics board meetings as changes that emerged through system development appeared to change the specifc form given to the project’s ethical aims. For example, as the project developed, a question for the ethics board was how far could an algorithm ‘learn’ and be changed before it was considered suffciently ‘new’ to challenge the ethical aim of the project to not introduce new algorithms? Furthermore, how much new data from bounding boxes, object classifcation and action states could be produced before it challenged the ethical principle to reduce data? This intersection of account-ability and accountability was not resolved in any particular moment, but became a focal point for my ethics board presentations and ensuing discussions and public reporting. 66 D. NEYLAND However, as the project and ethics board meetings progressed, my role in producing accounts became more diffcult. I was involved in making available an analysis of the account-able order of the system partly as a means to open the system to questions of accountability, which I would then publicly report and feed back to project members. At the same time, I was not just creating an intersection between account-ability and accountability, I risked being deeply involved in producing versions of the system’s account-able order which might steer ethics board members towards recognising that the system had achieved or failed to achieve its ethical aims and thus defuse or exacerbate accountability concerns. I was the algorithm’s proxy, mediating its ability to grasp everyday life through my ability to grasp the details of its abilities. As one of the Data Protection Offcers on the ethics board asked, ‘What is Daniel’s role? How can he ensure he remains impartial?’ Rather than try to resolve this problem in a single ethics board meeting, I sought instead to turn this issue of my own accountability into a productive tension by bringing as much as possible to the ethics board. My own developing account of the account-able order of the algorithmic system, the computer scientists, end-users and the technology as it developed could all be drawn together in ethics board meetings. The result was not a single, agreed upon expert view on the system. In place of a single account, the meetings became moments for different views, evidence, material practices and so on to be worked through. The effect was to intersect account-ability and accountability in a way that enabled questions and attributions of algorithmic responsibility and openness to be brought into the meetings and discussed with ethics board members, computer scientists, the system and my own work and role in the project. Accountability was not accomplished in a single moment, by a single person, but instead was distributed among project members and the ethics board and across ongoing activities, with questions taken back to the project team between meetings and even to be carried forward into future projects after the 