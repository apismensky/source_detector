exclusions and careful calculation provided the means for the coordinators to try and build a compelling narrative that would achieve this performative effect. Rather than relying on a single utterance (as in Austin’s illustrative examples of performativity), accomplishing this effect relied on the Report’s extended narrative as a means to provide a particular kind of evidence (not of technical effcacy, but of investment potential) on a particular scale (across industries and geographies). In place of uncertainty derived from 44 competitors came the assertion that none of the competitors could deliver as sophisticated a solution as that promised by the project. In place of a concern with governments cutting budgets in times of austerity came the assertion that governments must look to cut costs and therefore should look for the kind of cheap storage solutions that auto-deletion technologies could provide. In place 130 D. NEYLAND of a concern that a new surveillance system might attract privacy-based criticism came the assertion that this system carried with it and provided a response to that privacy criticism. And in place of any concern from among project members that the technology didn’t work came nothing; technological inadequacies were excluded from the Report and its audience. Building this compelling narrative (Simakova and Neyland 2008) was central to accomplishing the performative effect. From the preceding analysis, we can see that our algorithms are not left to fend for themselves, abandoned as a result of their technical ineffcacies. Neither are they exactly excused from any further role in the project. They are in the Exploitation Report, but their lack of effcacy is excluded. To accomplish the performative effect, they need to be present as an investable entity, at the same moment as key features of their activity are absent. The orderly world of the investment proposition is as much dependent on these absences as the presence of the algorithms. Understanding performativity is not then restricted to single speech acts or even the content of the Exploitation Report alone, but requires understanding the concerted efforts to segment, calculate, and prepare a world of people, things, processes, resources and relationships that the investors can enter. Preparing the putative world for investors involved these presences and absences, but also the possibility of accumulating something further. This built on the segmentation, calculation and preparation work to narrate future returns on investments from building an ethical, algorithmic surveillance system. The system could be invested in and might go on to do the work that might be required of companies in the emerging and changing Data Protection and privacy landscape where such matters as a right to be forgotten (see Chapter 4) have gained momentum. Complying with policy requirements and customer expectations of privacy, and delegating this compliance to our algorithms (or at least, future renditions of our algorithms), might become a marketable good and attain a value. Following many weeks of labour by the project coordinators in producing ‘The Exploitation Report’, the preparation work of segmentation, calculation and absenting of certain forms of data (on technical effcacy) was hidden. Making sense of the performativity through which an investment proposition is given effect requires an understanding of this preparatory work, but also cannot ignore the compelling narrative in which it is subsequently involved. Market value here achieves its potential 6 MARKET VALUE AND THE EVERYDAY LIFE OF THE ALGORITHM 131 through the segmentation of geographies, technologies, competitors and customers, the apportioning of a calculative value (or non-value) to these entities and evidence from third parties to support the values evidenced. This work is only partly evident in the Report. The outcomes rather than the means of calculation, for example, are made prominent. However, the Report itself also needs consideration. The preparation work to segment, calculate and value entities had to be drawn into a compelling narrative that supported the future development of the algorithmic system. Work was thus done to connect things we all know are happening now (such as government austerity measures and the need to cut budgets) with features of the technological future (such as deletion), to generate a compelling narrative for investment in the algorithmic technologies (in this instance, that austerity measures and cost-cutting could be achieved through deletion by cutting data storage costs). And other things that we know are taking place (such as the introduction of the EU General Data Protection Regulation) could be connected with a range of required activities (compliance with the legislation) that could be accomplished via our algorithms. Certainty in the narration of problems (that these problems exist and will be faced by these customers) and solutions (that 