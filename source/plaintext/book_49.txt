see-able integrity of the artwork.17 Declarations of the nature of an artwork (its material and visual integrity), also appear to be morally oriented such that constituting the nature of a painting as correctly attributed to an artist, becomes a means to constitute the moral integrity of: the material properties and practices of seeing that have established the painting as what it is (as genuine or as fake and thereby morally corrupt); its human supporters as what they are (as, for example, neutral art experts or morally dubious individuals who may be seeking fnancial gain from a painting’s material and visual integrity). The material, visual, moral question of integrity becomes: can the object to hand demonstrate the properties for which it ought to be able to account, indexically pointing towards a context for establishing the integrity of the material properties of the artwork and the practices through which it has been seen by its supporters? Can it maintain a relation of undoubted correspondence between what it appears to be and what it interactionally becomes? In a similar manner to technology demonstrations, fakes appear to incorporate a concern for revelation and concealment (revealing a husband’s method of suicide, concealing the fact he is still alive), temporal oscillation (authorities in buying a fake bomb detector, also buy a future into the present, imagined and indexically created through the technology’s apparent capabilities) and the careful selection and positioning of audience within the narrative structure being deployed (particularly 100 D. NEYLAND when faking a marriage or other notable social ceremony). However, fakes (particularly fake artworks) alert us to the possibility of also considering questions of visual, material and moral integrity in forms of demonstration. Returning to our algorithms will allow us to explore these questions of integrity in greater detail. Demonstrating Algorithms From their initial discussions of system architecture and experimentation with grasping the human-shaped object (see Chapter 2), to the start of system testing, demarcating relevant from irrelevant data and building a deleting machine (see Chapter 4), the project team had retained a confdence in the project’s premise. The aim was to develop an algorithmic surveillance system for use, initially, in a train station and airport that would sift through streams of digital video data and select out relevant images for human operatives. As I suggested in Chapter 2, the idea was to accomplish three ethical aims, to reduce the amount of visual video data that was seen by operatives, to reduce the amount of data that was stored by deleting irrelevant data and to not develop any new algorithms in the process. Up until the problems experienced with the deletion system (see Chapter 4), achieving these aims had been a diffcult and challenging task, but one in which the project team had mostly succeeded. Yet the project had never been just about the team’s own success: the project and in particular the algorithmic system needed to demonstrate its success (and even become a marketable good, see Chapter 6). From the project proposal onwards, a commitment had always been present to put on three types of demonstration for three distinct kinds of audience. As the person responsible for ethics in the project, I would run a series of demonstrations for ethical experts, policy makers (mostly in the feld of data protection) and academics who would be called upon to hold to account the ethical proposals made by the project. End-users from the train station and airport would also be given demonstrations of the technology as an opportunity to assess what they considered to be the potential strengths and weaknesses of the system. Finally, the project funders would be given a demonstration of the technology ‘live’ in the airport at the end of the project, as an explicit opportunity to assess the merits, achievements, failures and future research that might emanate from the project. We will take each of these forms of demonstration in turn and look at the ways in which our algorithms now engage with the everyday and the questions of integrity these engagements provoke. 5 DEMONSTRATING THE ALGORITHM 101 Demonstrating Ethics I invited a group of ethical experts (including academics, data protection offcers, politicians and civil liberty organisations) to take part in a demonstration of the technology and also ran sponsored sessions at three conferences where academics could be invited along to demonstrations. The nature of these demonstrations at the time seemed partial (Strathern 2004), and in some ways deferred and delegated (Rappert 2001) the responsibility for ethical questions from me to the demonstration audiences. The demonstrations were partial in the sense that I could not use live footage as these events did not take place in the end-user sites and could only use footage of project participants acting out suspicious 