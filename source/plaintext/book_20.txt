this would achieve the conditions under which the algorithmic system could issue an alert to operatives. As the following fgure shows, once a close-cropped image of what could be classifed as a luggage-shaped object was deemed by the system to have lingered beyond a defned time and distance from its human-shaped object, then it would be highlighted in red and sent to operatives for confrmation and, potentially, further action (Fig. 2.5). In place of the concise elegance of the imprecise bounding box, this more precise pixel cropped form of parameterisation was computationally more demanding, requiring a little more time and more processing power. However, it was key to maintaining a set of results in these initial experimentations that satisfed the needs of the system as agreed with SkyPort and StateTrack and could be persuasive to all project partners. That is, it produced results that suggested the project was feasible and ought to continue (although as we will see in Chapter 5, problems with classifcation continued to be diffcult to resolve). The bounding boxes lacked the precision to give effect to the IF-THEN rules of the abandoned luggage algorithm. The human-shaped object was thus accomplished in two forms—as a bounding box and a more closely cropped image. The bounding boxes although somewhat crude were central to the next stages in algorithmic experimentation in Route Reconstruction and the issuing of alerts to operatives (see Chapter 3) and deletion (see Chapter 4). For now, our algorithm could be satisfed that it had been able to participate in at least a modifed, initial and hesitant, experimental form of everyday life. It had Fig. 2.5 An item of abandoned luggage 40 D. NEYLAND not succeeded entirely in meeting all the goals of the project yet, it had struggled to initially produce a set of results that could elegantly capture suffcient information to accurately and consistently identify abandoned luggage and had to be changed (to a pixel-based process), and it was reliant on digital maps and background subtraction, but it had nonetheless started to get into the action. Conclusion In this chapter, I have started to build a sense of the everyday life in which our algorithm was becoming a participant. In experimental spaces, our algorithm was starting to make a particular sense of what it means to be human and what it means to be luggage. The IF-THEN rules and the development of associated software/code, the building of a system architecture and set of components provided the grounds for rendering things like humans and luggage at stake. To return to Pollner’s (1974) work (set out in the Introduction), the algorithm was starting to set out the basis for delimiting everyday life. The algorithm was beginning to insist that the stream of digital video data fowing through the system acted on behalf of an account as either luggage-shaped or human-shaped or background to be ignored. In addressing the question how do algorithms participate in everyday life, we have started to see in this chapter that they participate through technical and experimental means. Tinkering with ways to frame the human-shaped object, decide on what might count as elegant through concision, satisfaction and persuasion, are all important ways to answer this question. But we can also see that this participation is hesitant. The bounding box is quite elegant for two of the system’s algorithmic processes (moving the wrong way and moving into a forbidden area) but not particularly persuasive or satisfactory for its third process (identifying abandoned luggage). And thus far, all we have seen is some initial experimentation, mostly involving the humanshaped objects of project participants. This experimentation is yet to fully escape the protected conditions of experimentation. As we will see in Chapters 4 and 5, moving into real time and real space, many of these issues in relation to algorithmic participation in everyday life have to be reopened. It is in subsequent chapters that we will start to look into how the algorithm becomes the everyday and how algorithms can even compose the everyday. For now, these questions have been expressed in limited 2 EXPERIMENTATION WITH A PROBABLE HUMAN-SHAPED OBJECT 41 ways, for example when the computer scientists joked about how they would like to change the airport architecture to match the needs of the system. In subsequent chapters, as questions continue regarding the ability of the algorithm to effectively participate in everyday life, these questions resurface. In the next chapter, we will look at how the algorithmic system could become accountable. This will pick up on themes mentioned in the Introduction on transparency and accountability and will explore in greater detail the means through which the everyday life of the algorithm could be made at stake. As the project upon which this book is based was funded in order to produce a more ethical algorithmic system, these questions of 