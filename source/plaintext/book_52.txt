(in)effcacy data to help shape how they might see the algorithms. The computer scientists also had a developing understanding of algorithmic vision (learning more about the precise ways that the system could not straightforwardly see different foor coverings or lighting 5 DEMONSTRATING THE ALGORITHM 105 conditions or manage different frame rates across different cameras). And some features of how our algorithms grasped everyday life were never resolved in the project. In the following image (Fig. 5.4), the algorithm has selected out a feature of the fxed attributes of the airport (a wall) as a luggage-shaped object, something that ought to be impossible using background subtraction as the wall ought to be part of the background map: Further, those involved in seeing in these demonstrations needs to be extended to incorporate our algorithms too. In the ethical demonstrations, to reveal to the audience but not the algorithm, that the data was recorded involved some integrity (those invited to hold the Fig. 5.1 A humanshaped object and luggage-shaped object incorrectly aggregated as luggage Fig. 5.2 A luggage-shaped object incorrectly classifed as separate from its human-shaped object 106 D. NEYLAND technology to account were at least apparently informed of the nature of the data being used and if the recorded nature of the data was concealed from the algorithm, then the demonstration could be presented as suffciently similar to using live data to maintain its integrity). However, following the disappointing results of the user demonstration and further discussions with the computer scientists regarding the recorded data used in the ethical demonstrations, it transpired that Fig. 5.3 A humanshaped object’s head that has been incorrectly classifed as a human in its own right, measured by the system as small and therefore in the distance and hence in a forbidden area, set up for the demonstration Fig. 5.4 Wall as a luggage-shaped object 5 DEMONSTRATING THE ALGORITHM 107 the algorithms were not entirely in the dark about the nature of the footage. The computer scientists had a developing awareness that the algorithms could see a space with greater or lesser confdence according to camera angles, lights, the material foor covering, how busy a space happened to be and so on. Using recorded data that only included ‘unproblematic’ footage enabled the algorithms to have the best chance of seeing the space and to be recorded seeing that space successfully. To replay these recordings as the same as live data, was to conceal the partially seeing algorithm (the algorithm that sees well in certain controlled conditions). Algorithmic vision (how the algorithm goes about seeing everyday life) and the constitution of the spaces in which the algorithms operate (including how the algorithms compose the nature of people and things) were entangled with questions of material, visual and moral integrity which we will return to below. However, frst and most pressing for the project team was the question of what to do about demonstrating the ethical surveillance system to project funders given the disastrous effcacy results. Demonstration for Project Funders A meeting was called among project participants following the end-user demonstration. The dominant theme of the discussion was what to do about the rapidly approaching demonstration to project funders given the results of the end-user demonstrations. This discussion was made particularly tense when one of the computer scientists pointed out that in the original project description, a promise had been made to do a demonstration to the project funders not only of the airport, but also of the other end-user location—the train station. Much of the discussion during the meeting was of the technical challenges that were becoming apparent of digitally mapping the fxed attributes of a space as complex as an airport in order for the algorithms to classify objects as humanshaped or not. And the further complexities of then mapping a train station too, of how both locations had camera angles not favoured by the algorithms (e.g. being too low), were both subject to changing lighting conditions and frame rates, multiple fooring material and were both busy with people and objects. 108 D. NEYLAND The following excerpts have been produced from feldnotes taken during the meeting. The frst option presented during the meeting was to use recorded data: Computer Scientist1: it doesn’t work well enough. We should use recorded data. [no response] The silence that followed the computer scientist’s suggestion was typical of what seemed to be multiple awkward pauses during the meeting. One reason for this might have been an ongoing difference among members of the project team as to how responsibility ought to be distributed for the disappointing end-user demonstration results. Another reason might also be a concern that to use recorded data was to effectively undermine the integrity of the fnal project 