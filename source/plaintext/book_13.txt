human and how ought we to know. And it awaits experimentation that opens up what might otherwise be a pristine laboratory space to new questions, new forms of liveliness. Experimentation began from the outset of the project in which the algorithm was a participant. We will begin here with the initial development of the project in order to provide a prior step to experimentation. Although the experimentation was more open than a controlled laboratory experiment, it was not free from any constraints or expectations. The experimentation had a broad purpose that was successively set and narrowed as the experimentation proceeded. What was being experimented upon and what was anticipated as the outcome of experimentation was the product of successive rounds of experimentation. To make sense of these expectations, we need to see how the project produced its algorithms in the frst place. The Algorithmic Project The project upon which this book is based began with an e-mail invitation: Would I be interested in participating in a project that involved the development of a new ‘ algorithmic’, ‘smart’ and ‘ethical’ video-based surveillance system? The project coordinator informed me that the project would involve a large technology frm (TechFirm1), two large transport frms where the technology would be tested and developed (SkyPort, which owns and operates two large European city airports, and StateTrack, a large European state railway) and two teams of computer scientists (from University 1, UK, and University 2, Poland) and that the project would be managed by a consultancy frm (Consultor, Spain). I was being invited to oversee the ethics of the technology under development and to provide an (at least partially) independent ethical assessment. The project would involve developing a system that would use algorithms to select security-relevant images from the CCTV systems of the airport and train station. It would use this ability to demarcate relevance as a basis for introducing a new, ethical, algorithmic system. The coordinator suggested the project would provide a location for experimentation with three ethical aims: that algorithms could be used to 2 EXPERIMENTATION WITH A PROBABLE HUMAN-SHAPED OBJECT 25 reduce the scope of data made visible within a video-based surveillance system by only showing ‘relevant’ images; that algorithms could be used to automatically delete the vast majority (perhaps 95%) of surveillance data that was not relevant; and that no new algorithms or surveillance networks would need to be developed to do so. These aims had been developed by the coordinator into an initial project bid. The coordinator hoped the ‘ethical’ qualities of the project were clear in the way the aims were positioned in the bid as a response to issues raised in popular and academic discussions about, for example, privacy, surveillance and excessive visibility (Lyon 2001; Davies 1996; Norris and Armstrong 1999; Bennett 2005; Van der Ploeg 2003; Taylor 2010; McCahill 2002) and concerns raised with algorithmic surveillance (Introna and Woods 2004). In particular, the project bid set out to engage with contemporary concerns regarding data retention and deletion, as very little data would be kept (assuming the technology worked). The proposal was a success, and the project was granted €2.8m (about $3.1m in mid-2015) under the European Union’s 7th Framework Programme. A means to fulfl the promises of ethical algorithms committed to the project bid would now have to be found. This set the scene for early rounds of experimentation. Establishing the Grounds for Experimentation and the Missing Algorithms The basis for initial experimentation within the project was a series of meetings between the project participants. Although there were already some expectations set in place by the funding proposal and its success, the means to achieve these expectations and the precise confguration of expectations had not yet been met. I now found myself sat in these meetings as an ethnographer, watching computer scientists talking to each other mostly about system architectures, media proxies, the fow of digital data—but not so much about algorithms. Attaining a position as an ethnographer on this project had been the result of some pre-project negotiation. Following the project coordinator’s request that I carry out an ethical review of the project under development, I had suggested that it might be interesting, perhaps vital, to carry out an assessment of the system under development. Drawing on recent work on ethics and design and ethics in practice,2 I suggested that what got to count as the ethics of an algorithm might not be easy 26 D. NEYLAND to anticipate at the start of a project or from a position entirely on the outside. It might make more sense to work with the project team, studying the development of the technology and feeding in ethical questions and prompts over the three years of the project. Although this seemed to be an 