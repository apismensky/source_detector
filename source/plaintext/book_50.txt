behaviour due to data protection concerns that would arise if footage were used of non-project participants (e.g. airport passengers) who had not consented to take part in the demonstrations. Using recorded footage at this point seemed more like a compromise than an issue of integrity; footage could be played to audiences of the User Interface and our algorithms selecting out human-shaped objects, action states (such as abandoned luggage) and even use footage of the Route Reconstruction system to replay those objects deemed responsible for the events. Audience members were invited to discuss the ethical advantages and disadvantages they perceived in the footage. If it raised questions of integrity to any extent, it was perhaps in the use of recorded footage. But audiences were made aware of the recorded nature of the footage and the project participants’ roles as actors. In place of a display of virtuosity (Collins 1988) or an attempt to manage revelation and concealment (Coopmans 2010) I (somewhat naively it turned out) aimed to put on demonstrations as moments where audiences could raise questions of the technology, free from a dedicated move by any wily demonstrator to manage their experience of seeing. Along with recorded footage, the audience were shown recordings of system responses; videos incorporated the technicalities of the Event Detection component of the system architecture, its selection procedures and provision of alerts. I took audiences through the ways in which the system put bounding boxes around relevant human-shaped and other objects deemed responsible for an action and showed a few seconds of footage leading up to and following an alert. At this moment, I thought I was giving audiences a genuine recording of the system at work for them to discuss. However, it later transpired that the recorded footage and system response, and my attestation that these were more or less realistic representations of system capabilities, each spoke of an integrity belied by later demonstrations. 102 D. NEYLAND End-User Demonstrations The limitations of these initial demonstrations became clear during a second form of demonstration, to surveillance operatives in the airport. Several members of the project team had assembled in an offce in the airport in order to give operatives an opportunity to see the more developed version of the technology in action. Unlike initial discussions around the system architecture or initial experimentation with grasping the humanshaped object (see Chapter 2), our algorithms were now expected to deliver a full range of competences in real time and real space.18 These demonstrations also provided an opportunity for operatives to raise issues regarding the system’s latest design (the User Interface, for example, had been changed somewhat), its strengths and limitations, and to ask any questions. This was to be the frst ‘live’ demonstration of the technology using a live feed from the airport’s surveillance system. Although Simakova (2010) talks of the careful preparations necessary for launching a new technology into the world and various scholars cite the importance of revelation and concealment to moments of demonstration (Smith 2009; Coopmans 2010; Collins 1988), this attempt at a ‘demonstration’ to end-users came to seem confdent, bordering on reckless in its apparent disregard of care and concealment. Furthermore, although there was little opportunity to select the audience for the test (it was made up from operatives who were available and their manager), there was also little done to position the audience, manage their experience of seeing, incorporate them into a compelling narrative or perform any temporal oscillation (between the technology now and how it might be in the future; Suchman 2011; Brown 2003; Brown and Michael 2003; Simakova 2010; Smith 2009). The users remained as unconfgured witnesses (Coopmans 2010; Woolgar 1991). Prior to the demonstration to end-users, the limited preparatory work of the project team had focused on compiling a set of metrics to be used for comparing the new algorithmic system with the existing conventional video-based surveillance system. An idea shared among the computer scientists in the project was that end-users could raise questions regarding the technology during a demonstration, but also be given the metric results as indicative of its effectiveness in aiding detection of suspicious events. The algorithmic and the conventional surveillance system would operate within the same temporal and spatial location of the airport and the operatives would be offered the demonstrators’ metric criteria as the basis for judging 5 DEMONSTRATING THE ALGORITHM 103 sameness (Pinch 1993). The metrics would show that the new technology, with its move to limit visibility and storage, was still at least as effective as the current system in detecting events, but with added ethics. This demonstration was designed to work as follows. The operatives 